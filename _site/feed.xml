<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-09-01T12:39:06+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">David Fabricius’ Portfolio</title><subtitle>En portefølje fra en datamatiker på 4. semester</subtitle><author><name>David</name></author><entry><title type="html">Logbog 3</title><link href="http://localhost:4000/2023/08/31/logbog3.html" rel="alternate" type="text/html" title="Logbog 3" /><published>2023-08-31T10:45:13+02:00</published><updated>2023-08-31T10:45:13+02:00</updated><id>http://localhost:4000/2023/08/31/logbog3</id><content type="html" xml:base="http://localhost:4000/2023/08/31/logbog3.html"><![CDATA[<p>Jeg snakkede med min lærer Thomas omkring hvad jeg skal gøre mht. single page application og Nolek. Jeg fortalte ham mine lidt spredte tanker omkring applikationen indtil videre. SPA'en skal kunne modtage inputs til ML delen af mit andet valgfag, dette kunne være information omkring et lækage testobjekt.</p>
<p>Derudover skal man også i SPA'en kunne logge ind, oprette et lægkage testobjekt med billede, dvs. at uploade billeder, og registrere om der er lækage ved hvert "sniffing point", og kunne redigere dette</p>
<p>Min lærer forslog at jeg lavede use case diagrammer eller navigations diagrammer, og et wireframe diagram der viser hvordan applikationen kommer til at se ud, både som mobil og desktop. Dette kunne jeg så tage med til det næste Nolek møde. Der blev også forslået at jeg laver krav-specifikation til det næste Nolek møde</p>]]></content><author><name>David</name></author><summary type="html"><![CDATA[Jeg snakkede med min lærer Thomas omkring hvad jeg skal gøre mht. single page application og Nolek. Jeg fortalte ham mine lidt spredte tanker omkring applikationen indtil videre. SPA'en skal kunne modtage inputs til ML delen af mit andet valgfag, dette kunne være information omkring et lækage testobjekt. Derudover skal man også i SPA'en kunne logge ind, oprette et lægkage testobjekt med billede, dvs. at uploade billeder, og registrere om der er lækage ved hvert "sniffing point", og kunne redigere dette Min lærer forslog at jeg lavede use case diagrammer eller navigations diagrammer, og et wireframe diagram der viser hvordan applikationen kommer til at se ud, både som mobil og desktop. Dette kunne jeg så tage med til det næste Nolek møde. Der blev også forslået at jeg laver krav-specifikation til det næste Nolek møde]]></summary></entry><entry><title type="html">Logbog 2</title><link href="http://localhost:4000/2023/08/29/logbog2.html" rel="alternate" type="text/html" title="Logbog 2" /><published>2023-08-29T16:45:13+02:00</published><updated>2023-08-29T16:45:13+02:00</updated><id>http://localhost:4000/2023/08/29/logbog2</id><content type="html" xml:base="http://localhost:4000/2023/08/29/logbog2.html"><![CDATA[<p>Vi havde i dag et møde med processgruppen, vi viste vores portfolio, og der blev snakket om hvordan vi kunne forbedre den. Vi snakkede om hvad vi skal skrive, hvad vi skal reflektere om, og hvordan vi sætter mål. Der blev forslået at vi kategoriserer vores blog indlæg, så jeg har nu ændret denne portefølje til at have kategorier.</p>
<p>Jeg skal sætte nogle overordnede mål for dette semester projekt, det behøver ikke nødvendigvis at være helt præcist endnu, og det kan være at det bliver ændret undervejs, men vi skal stille mål op som vi kan sigte efter. Vi snakkede også om hvor teknisk det vi skriver om skal være, der blev forklaret at det skal være somom vi skriver til en anden datamatiker studerende. Derudover skal vi også sørge for at ikke kun fokusere på et valgfag men begge.</p>]]></content><author><name>David</name></author><summary type="html"><![CDATA[Vi havde i dag et møde med processgruppen, vi viste vores portfolio, og der blev snakket om hvordan vi kunne forbedre den. Vi snakkede om hvad vi skal skrive, hvad vi skal reflektere om, og hvordan vi sætter mål. Der blev forslået at vi kategoriserer vores blog indlæg, så jeg har nu ændret denne portefølje til at have kategorier. Jeg skal sætte nogle overordnede mål for dette semester projekt, det behøver ikke nødvendigvis at være helt præcist endnu, og det kan være at det bliver ændret undervejs, men vi skal stille mål op som vi kan sigte efter. Vi snakkede også om hvor teknisk det vi skriver om skal være, der blev forklaret at det skal være somom vi skriver til en anden datamatiker studerende. Derudover skal vi også sørge for at ikke kun fokusere på et valgfag men begge.]]></summary></entry><entry><title type="html">Delmål Uge 35-36</title><link href="http://localhost:4000/2023/08/28/partgoals2.html" rel="alternate" type="text/html" title="Delmål Uge 35-36" /><published>2023-08-28T16:45:13+02:00</published><updated>2023-08-28T16:45:13+02:00</updated><id>http://localhost:4000/2023/08/28/partgoals2</id><content type="html" xml:base="http://localhost:4000/2023/08/28/partgoals2.html"><![CDATA[<p>Delmål 1: Færdiggøre "Neural networks from scratch"</p>
<p>Delmål 2: Få overblik over det data, jeg forventer at få, fra Nolek i de næste to uger</p>
<p>Delmål 3: Se tutorial omkring React, frontend design og mobile SPA </p>
<p>Delmål 4: Lave use case diagrammer til SPA</p>
<p>Delmål 5: Lave en mere specifik kravspecifikation til det jeg skal lave mht. SPA og ML</p>

<img src="/img/posts/delmål2.png" style="max-width: 100%">]]></content><author><name>David</name></author><summary type="html"><![CDATA[Delmål 1: Færdiggøre "Neural networks from scratch" Delmål 2: Få overblik over det data, jeg forventer at få, fra Nolek i de næste to uger Delmål 3: Se tutorial omkring React, frontend design og mobile SPA Delmål 4: Lave use case diagrammer til SPA Delmål 5: Lave en mere specifik kravspecifikation til det jeg skal lave mht. SPA og ML]]></summary></entry><entry><title type="html">Codecademy’s “Build a Machine Learning Model with Python”</title><link href="http://localhost:4000/2023/08/28/codecademy.html" rel="alternate" type="text/html" title="Codecademy’s “Build a Machine Learning Model with Python”" /><published>2023-08-28T16:45:13+02:00</published><updated>2023-08-28T16:45:13+02:00</updated><id>http://localhost:4000/2023/08/28/codecademy</id><content type="html" xml:base="http://localhost:4000/2023/08/28/codecademy.html"><![CDATA[<p>Jeg har gennemgået 2/3 dele af Codecademy’s “Build a Machine Learning Model with Python”. Man lærer hvordan det er at arbejde med store mængder data, og forberede det til at blive trænet på en model. Udover dette introducerede den, en del længere, tutorial mange begreber, koncepter og algoritmer man bruger i machine learning, men gik heller ikke alt for meget i dybden med de mere komplekse koncepter. Tutorialen “Build a Machine Learning Model with Python” var netop kun en en introduktion for nybegyndere. Jeg havde håbet at lære mere om neurale netværk. </p>
<h3>Regression vs. Klassifikation</h3>
<p>Tutorialen forklarer forskellen mellem regression og klassifikation. Regression bliver brugt til at forudse kontinuerlige outputs, mens klassifikation bliver brugt til diskrete (discrete) outputs/label, som tilhører en bestemt kategori som output.  Kontinuerlige eksempel: Forudse højden af en plante i forhold til mængde regn. Klassifikation eksempel: forudse om en mail er spam eller ej. Dette eksempel er en “binary classification”, der findes også multi-class(samme som binary, bare med flere end to) og multi-label(hvor der er muligt at have flere rigtige labels som output) klassifikation. </p>
<h3>Typer af Modeller: Supervised & Unsupervised Learning</h3>
<p>Der er også to forskellige typer af modeller: Supervised Learning & Unsupervised Learning. Ved Supervised Learning er dataen “labeled” og programmet lærer at forudse outputtet ud fra labeled input data. Ved unsupervised learning er data’en “unlabled” og programmet lærer fra mønsteret og strukturen i data’en. De inputs man træner ens model på er kaldt “features”, og det input man gerne vil have modellen til at forudse er kaldt en “label”.</p>
<h3>Liniær Regression</h3>
<p>Tutorialen begynder med en af de lidt nemmere emner: liniær regression.  Ved lineær regression finder algoritmen den bedste rette linje til data punkterne, fx huspriser ud fra husets størrelse. Der blev vist hvordan man selv skriver algoritmen og derefter hvordan man bruger scikit-learns linear regression model. Man kan finde den bedste rette linje ved at justere hældning “slope” og “intercept” en konstant, der afgør, hvor grafen skærer y-aksen, som man måske kan huske fra matematik er den liniære funktion y = m*x+b, hvor x er input. Man kan også tænke på det som at hældning er en vægt og intercept er bias, hvilket bliver brugt i neurale netværk. Så man ganger input med vægten og plusser bias. Der blev derefter vist hvordan man laver “multiple linear regression” hvor der er flere end en slope/vægte og input. Generelt for mange af disse machine learning algoritmer handler det om at justere vægtene ud fra “loss”, altså hvor langt fra det man forudser, gættet, er fra det faktiske label, dvs. det man gerne vil forudse. </p>
<h3>Logistisk Regression</h3>
<p>Jeg lærte også om logistisk regression, logistisk regression bruger binary klassifikation(0/1 eller True/False). Man bruger en sigmoid kurve, når x = 0 er y = 0.5. Når x er stor er y meget tæt på 1, og når x er lille er y meget tæt på 0.  Der er et “threshold“ der afgør resultatet, om det er 0 eller 1, for eksempel om der er et læk eller ej, dette kunne fx være 0.5. Man bruger faktisk liniær regression til at “fodre” sigmoid funktionen for at få en sandsynlighed. Som man måske kan huske fra statistik, er en sandsynlighed altid mellem 0 og 1. For at finde ud af hvor godt modellen gør det, beregner man “log-loss”. Denne funktion måler forskellen mellem vores forudsigelser (output fra sigmoid funktionen) og de faktiske værdier (sandheder). Hvis den forudsagte sandsynlighed er tæt på den sande værdi, giver det et lavt tab, og omvendt med et højt tab. Log-loss:
    <p>L(y,p)=−ylog(p)−(1−y)log(1−p)</p>
    y er den faktiske værdi (0 eller 1), og p er den forudsagte sandsynlighed for at den faktiske klasse er 1. Hvis denne sandsynlighed er tæt på den sande, giver det et lavt tab. 
    Når y(den faktiske værdi) er 1(y = 1), bliver formlen: L = -log(p), hvis p er tæt på 1(forudsigelsen er korrekt) kommer tabet til at være meget småt. Hvis p er tæt på 0 (forudsigelsen er forket) bliver tabet et stort nummer. 
    Omvendt hvis den sande værdi er 0 bliver formlen: -log(1-p) hvis p er tæt på 0(forudsigelsen er korrekt) kommer tabet til at være meget småt. Hvis p er tæt på 1 (forudsigelsen er forket) bliver tabet et stort nummer. 
    
    Dog var denne information ikke noget codecademy valgte at gå over, så det er noget jeg selv har fundet på nettet.</p>
<h3>Perceptroner</h3>
<p>Der blev også introduceret konceptet om en “perceptron”. En perceptron er et grudlæggende element i et neuralt netværk, og kan sammenlignes med et neuron i hjernen. Den tager inputs, ganger dem med vægte, og summer disse vægtede inputs op (weighted sum). Hvis de summerede vægtede inputs går over en bestemt grænse producerer perceptronen et specifikt output. Dette output er resultatet af en "activation function". En activation function bestemmer, hvilken output en perceptron skal give baseret på de indkommende inputs, hvilket gør det muligt for netværket at lære komplekse mønstre. 

    Derudover lærte jeg fra tutorialen og om: naive bayes classifier og Bayes’ theorem, normalisering, k-nearest neighbour og decision trees.
    
    Da jeg gerne vil arbejde med enten logistisk regression eller et neuralt netværk i ML-valgfaget, og Codecademy’s tutorial ikke gik i dybden med neurale netværk, valgte jeg at begynde med at studere neurale netværk specifikt.  Jeg begyndte på en youtube tutorial “Neural Networks from Scratch”.</p>]]></content><author><name>David</name></author><summary type="html"><![CDATA[Jeg har gennemgået 2/3 dele af Codecademy’s “Build a Machine Learning Model with Python”. Man lærer hvordan det er at arbejde med store mængder data, og forberede det til at blive trænet på en model. Udover dette introducerede den, en del længere, tutorial mange begreber, koncepter og algoritmer man bruger i machine learning, men gik heller ikke alt for meget i dybden med de mere komplekse koncepter. Tutorialen “Build a Machine Learning Model with Python” var netop kun en en introduktion for nybegyndere. Jeg havde håbet at lære mere om neurale netværk. Regression vs. Klassifikation Tutorialen forklarer forskellen mellem regression og klassifikation. Regression bliver brugt til at forudse kontinuerlige outputs, mens klassifikation bliver brugt til diskrete (discrete) outputs/label, som tilhører en bestemt kategori som output. Kontinuerlige eksempel: Forudse højden af en plante i forhold til mængde regn. Klassifikation eksempel: forudse om en mail er spam eller ej. Dette eksempel er en “binary classification”, der findes også multi-class(samme som binary, bare med flere end to) og multi-label(hvor der er muligt at have flere rigtige labels som output) klassifikation. Typer af Modeller: Supervised & Unsupervised Learning Der er også to forskellige typer af modeller: Supervised Learning & Unsupervised Learning. Ved Supervised Learning er dataen “labeled” og programmet lærer at forudse outputtet ud fra labeled input data. Ved unsupervised learning er data’en “unlabled” og programmet lærer fra mønsteret og strukturen i data’en. De inputs man træner ens model på er kaldt “features”, og det input man gerne vil have modellen til at forudse er kaldt en “label”. Liniær Regression Tutorialen begynder med en af de lidt nemmere emner: liniær regression. Ved lineær regression finder algoritmen den bedste rette linje til data punkterne, fx huspriser ud fra husets størrelse. Der blev vist hvordan man selv skriver algoritmen og derefter hvordan man bruger scikit-learns linear regression model. Man kan finde den bedste rette linje ved at justere hældning “slope” og “intercept” en konstant, der afgør, hvor grafen skærer y-aksen, som man måske kan huske fra matematik er den liniære funktion y = m*x+b, hvor x er input. Man kan også tænke på det som at hældning er en vægt og intercept er bias, hvilket bliver brugt i neurale netværk. Så man ganger input med vægten og plusser bias. Der blev derefter vist hvordan man laver “multiple linear regression” hvor der er flere end en slope/vægte og input. Generelt for mange af disse machine learning algoritmer handler det om at justere vægtene ud fra “loss”, altså hvor langt fra det man forudser, gættet, er fra det faktiske label, dvs. det man gerne vil forudse. Logistisk Regression Jeg lærte også om logistisk regression, logistisk regression bruger binary klassifikation(0/1 eller True/False). Man bruger en sigmoid kurve, når x = 0 er y = 0.5. Når x er stor er y meget tæt på 1, og når x er lille er y meget tæt på 0. Der er et “threshold“ der afgør resultatet, om det er 0 eller 1, for eksempel om der er et læk eller ej, dette kunne fx være 0.5. Man bruger faktisk liniær regression til at “fodre” sigmoid funktionen for at få en sandsynlighed. Som man måske kan huske fra statistik, er en sandsynlighed altid mellem 0 og 1. For at finde ud af hvor godt modellen gør det, beregner man “log-loss”. Denne funktion måler forskellen mellem vores forudsigelser (output fra sigmoid funktionen) og de faktiske værdier (sandheder). Hvis den forudsagte sandsynlighed er tæt på den sande værdi, giver det et lavt tab, og omvendt med et højt tab. Log-loss: L(y,p)=−ylog(p)−(1−y)log(1−p) y er den faktiske værdi (0 eller 1), og p er den forudsagte sandsynlighed for at den faktiske klasse er 1. Hvis denne sandsynlighed er tæt på den sande, giver det et lavt tab. Når y(den faktiske værdi) er 1(y = 1), bliver formlen: L = -log(p), hvis p er tæt på 1(forudsigelsen er korrekt) kommer tabet til at være meget småt. Hvis p er tæt på 0 (forudsigelsen er forket) bliver tabet et stort nummer. Omvendt hvis den sande værdi er 0 bliver formlen: -log(1-p) hvis p er tæt på 0(forudsigelsen er korrekt) kommer tabet til at være meget småt. Hvis p er tæt på 1 (forudsigelsen er forket) bliver tabet et stort nummer. Dog var denne information ikke noget codecademy valgte at gå over, så det er noget jeg selv har fundet på nettet. Perceptroner Der blev også introduceret konceptet om en “perceptron”. En perceptron er et grudlæggende element i et neuralt netværk, og kan sammenlignes med et neuron i hjernen. Den tager inputs, ganger dem med vægte, og summer disse vægtede inputs op (weighted sum). Hvis de summerede vægtede inputs går over en bestemt grænse producerer perceptronen et specifikt output. Dette output er resultatet af en "activation function". En activation function bestemmer, hvilken output en perceptron skal give baseret på de indkommende inputs, hvilket gør det muligt for netværket at lære komplekse mønstre.]]></summary></entry><entry><title type="html">Litteraturliste</title><link href="http://localhost:4000/2023/08/28/litteraturliste.html" rel="alternate" type="text/html" title="Litteraturliste" /><published>2023-08-28T14:45:13+02:00</published><updated>2023-08-28T14:45:13+02:00</updated><id>http://localhost:4000/2023/08/28/litteraturliste</id><content type="html" xml:base="http://localhost:4000/2023/08/28/litteraturliste.html"><![CDATA[<p>Codecademy’s “Build a Machine Learning Model with Python”</p>
<p>https://www.codecademy.com/learn/paths/machine-learning</p>
<br>
<p>Neural Networks from Scratch</p>
<p>https://youtu.be/Wo5dMEP_BbI?si=IEQGz_ROyoks0c7C</p>
<br>
<p>Coursera - neural networks deep learning</p>
<p>https://www.coursera.org/learn/neural-networks-deep-learning</p>]]></content><author><name>David</name></author><summary type="html"><![CDATA[Codecademy’s “Build a Machine Learning Model with Python” https://www.codecademy.com/learn/paths/machine-learning Neural Networks from Scratch https://youtu.be/Wo5dMEP_BbI?si=IEQGz_ROyoks0c7C Coursera - neural networks deep learning https://www.coursera.org/learn/neural-networks-deep-learning]]></summary></entry><entry><title type="html">Logbog 1</title><link href="http://localhost:4000/2023/08/21/logbog1.html" rel="alternate" type="text/html" title="Logbog 1" /><published>2023-08-21T16:45:13+02:00</published><updated>2023-08-21T16:45:13+02:00</updated><id>http://localhost:4000/2023/08/21/logbog1</id><content type="html" xml:base="http://localhost:4000/2023/08/21/logbog1.html"><![CDATA[<p>Vi havde i dag et gruppemøde, hvor vi diskuterede akitekturen for det samlede produkt. Vi lavede en domænemodel og en skitse af den tænkte akitektur, selvom det højest sandsynligt ændre sig i fremtiden</p>
<img src="/img/posts/arkitektur.png" style="max-width: 100%"> 
<p>Som man kan se er der en app og en single page application der sender requests til en API gateway, før det når til API'en går det igennem en firewall/proxy, ved API'en bliver requesten sendt videre ud afhængigt af hvad det er der bliver efterspurgt. Det kan være at SPA'en sender data til en ML model, eller til en microservice</p>
<img src="/img/posts/domaenemodel.png" style="max-width: 100%"> 
<p>Der skal være et test objekt, og hvert testobjekt har en til mange sniffing points, og til hver sniffing point findes der et testobjekt. Testresultatet er tilknyttet et sniffing point, der er en og op til mange testresultater pr. sniffing point.
    Begrundelse er tilknyttet et testresultat, testresulat har nul til mange begrundelser.
    Begrundelse har en bruger, og en bruger kan give ingen til mange begrundelser. 
    En bruger kan lave nul til mange testresultater, testresultater har altid kun en bruger</p>]]></content><author><name>David</name></author><summary type="html"><![CDATA[Vi havde i dag et gruppemøde, hvor vi diskuterede akitekturen for det samlede produkt. Vi lavede en domænemodel og en skitse af den tænkte akitektur, selvom det højest sandsynligt ændre sig i fremtiden Som man kan se er der en app og en single page application der sender requests til en API gateway, før det når til API'en går det igennem en firewall/proxy, ved API'en bliver requesten sendt videre ud afhængigt af hvad det er der bliver efterspurgt. Det kan være at SPA'en sender data til en ML model, eller til en microservice Der skal være et test objekt, og hvert testobjekt har en til mange sniffing points, og til hver sniffing point findes der et testobjekt. Testresultatet er tilknyttet et sniffing point, der er en og op til mange testresultater pr. sniffing point. Begrundelse er tilknyttet et testresultat, testresulat har nul til mange begrundelser. Begrundelse har en bruger, og en bruger kan give ingen til mange begrundelser. En bruger kan lave nul til mange testresultater, testresultater har altid kun en bruger]]></summary></entry><entry><title type="html">Machine Learning i Praksis: Fra Dataindsamling til Træning</title><link href="http://localhost:4000/2023/08/21/overordnetML.html" rel="alternate" type="text/html" title="Machine Learning i Praksis: Fra Dataindsamling til Træning" /><published>2023-08-21T16:45:13+02:00</published><updated>2023-08-21T16:45:13+02:00</updated><id>http://localhost:4000/2023/08/21/overordnetML</id><content type="html" xml:base="http://localhost:4000/2023/08/21/overordnetML.html"><![CDATA[<p>Dataindsamling og Forbehandling → Forbehandle data for at håndtere manglende værdier, outliers og normaliser dataene om nødvendigt.

    Indsamlig af relevante data er det første skridt ved ML. Når der er indsamlet data, er det vigtigt at forbehandle data. Det kan være at man for eksempel skal håndter manglende værdier ved enten at fjerne dem eller erstatte dem med gennemsnitsværdier eller medianværdier. Man skal også identificere og håndtere outliers, altså data punkter der ligger meget langt væk fra resten. Hvis dataen man skal bruge er i en helt anden skala fra hinanden bliver man nødt til at normalisere dataene.</p>

<p>Finde hoved features i data → Identificer de hoved-features, der kan påvirke en lækages opståen.

    Det er vigtigt at identificere de vigtigste features i dataen, da de kan have en stor indflydelse på modellens præstation.</p>

<p>Modelvalg → classification eller regression?

    Valget mellem klassifikation og regression afhænger af den type output, man ønsker fra ens model. Hvis man gerne vil have en kategori forudset så er det klassifikation man skal bruge, foreksempel om der er læk på et punkt (ja/nej). Med regression forudser man en kontinuerlig værdi, fx en probability/sandsynlighed af et læk på et punkt.</p>
<p>Træning → split data op i træning og validerings sæt, og så derefter test på validering.

    Modellen trænes på træningssættet. Modellen præstation testes på valideringssættet.  </p>]]></content><author><name>David</name></author><summary type="html"><![CDATA[Dataindsamling og Forbehandling → Forbehandle data for at håndtere manglende værdier, outliers og normaliser dataene om nødvendigt.]]></summary></entry><entry><title type="html">Arbejdsproces med KanBan</title><link href="http://localhost:4000/2023/08/21/kanban.html" rel="alternate" type="text/html" title="Arbejdsproces med KanBan" /><published>2023-08-21T16:45:13+02:00</published><updated>2023-08-21T16:45:13+02:00</updated><id>http://localhost:4000/2023/08/21/kanban</id><content type="html" xml:base="http://localhost:4000/2023/08/21/kanban.html"><![CDATA[<p>Jeg har tænkt mig at bruge en Kanban-tavle til at visualisere mine opgaver(krav) i forskellige faser, og følge progressionen i dem. Jeg har oprettet kolonner som "In Progress" og "Done" på Kanban-tavlen. Jeg har desuden også en "projekt backlog" kolonne hvor de store overordnede dele bliver sat på som jeg skal lave over semesteret, de bliver hovedsageligt nedbrudt i mindre dele, medmindre det ikke er nødvendigt og flyttet over i delmål kolonnen. Når tiden er kommet til at jeg skal i gang med en specifik del/item, bliver de sat over i in-progress fasen. Jeg opdaterer Kanban tavlen løbende. Jeg håber at det vil give mig et bedre overblik, over det kommende arbejde jeg  vil foretage mig.</p>]]></content><author><name>David</name></author><summary type="html"><![CDATA[Jeg har tænkt mig at bruge en Kanban-tavle til at visualisere mine opgaver(krav) i forskellige faser, og følge progressionen i dem. Jeg har oprettet kolonner som "In Progress" og "Done" på Kanban-tavlen. Jeg har desuden også en "projekt backlog" kolonne hvor de store overordnede dele bliver sat på som jeg skal lave over semesteret, de bliver hovedsageligt nedbrudt i mindre dele, medmindre det ikke er nødvendigt og flyttet over i delmål kolonnen. Når tiden er kommet til at jeg skal i gang med en specifik del/item, bliver de sat over i in-progress fasen. Jeg opdaterer Kanban tavlen løbende. Jeg håber at det vil give mig et bedre overblik, over det kommende arbejde jeg vil foretage mig.]]></summary></entry><entry><title type="html">Projekt og valgfag</title><link href="http://localhost:4000/2023/08/15/valgfagogprojekt.html" rel="alternate" type="text/html" title="Projekt og valgfag" /><published>2023-08-15T16:45:13+02:00</published><updated>2023-08-15T16:45:13+02:00</updated><id>http://localhost:4000/2023/08/15/valgfagogprojekt</id><content type="html" xml:base="http://localhost:4000/2023/08/15/valgfagogprojekt.html"><![CDATA[<p>Mht. machine learning, har vi talt med nolek omkring at det kunne bruges til at forudse/gætte hvor sandsynligheden er højest for at lækket sker på et bestemt punkt, ud fra det data virksomheden har. Det kan også være at det bliver et input af lækage data fra deres hardware, som så giver det punkt der har højest risiko for læk (istedet for et enkelt punkt). Det kunne gøres med fx multiple liniar regression, logistisk regression, eller neuralt netværk, regner med at det bliver supervised learning, dvs. labeled data. Det er svært at sige hvordan det præcis bliver inden, men forventer at nolek giver nogle store dataset at arbejde med.</p>

<p>Jeg har både overvejet Appudvikling og single page applications, jeg var ikke sikker på hvad der vil være mest brugbart i forhold til produktet vi sammen laver i vores produktgruppe. Der bliver i produktgruppen lavet en app, og jeg overvejede om det ville give mest mening at have Appudvikling som valgfag, så jeg kunne tilføje til den der i forvejen bliver lavet, i stedet for en single page application. Men siden der skal uploades flere billeder til den app, og muligvis login funktionalitet, kan det være at det er bedre at lave en single page application til det. Jeg kunne forestille mig at det ville være nemmere at administere upload af flere billeder på desktop, men det kommer også til at være mulighed for at bruge den til mobil i en browser. Mht single page applications, kunne jeg godt tænke mig at lave noget med en af de pupulære javascript biblioteker(React, Vue, Angular), så en dynamisk hjemmeside, hvor der udover billede upload, og måske login, bliver vist nogle resultater fra det vedrørende ML, hvor resultatet fra ML præsenteres, hvor man kan få info omkring ricisi om læk.</p>

<p>Vi mødes med Nolak igen snart, hvor jeg forventer at vi hører nærmere omkring de specifikke krav/produktet og hvordan det kan udføres. Det kommer meget an på hvordan deres data som de giver ser ud.</p>
<p>Det samlede system kommer til at bestå af en android app og en SPA hvor man registerer lækagetest, dette kunne være en test af et rørsystem fra et køleskab, hvor man makerer hvordan testen er gået, ud fra de enkelte lækage punkter, også kaldt “sniffing points”.  </p>
<img src="/img/posts/nolek_product_example.png" style="max-width: 100%"> 
<p>Mere specifikt skal appen og SPA'en bestå af: Et felt hvor et billede af det rørsystem som man tester, på dette billede vises de “sniffing points” hvor lækagen bliver dedekteret. Der skal være knapper til hvert lækage punkt hvor man kan trykke om de er okay eller ej, dvs om der er et læk. Der skal også være en menu hvor man kan vælge imellem de forskellige systemer man tester. Alle test bliver gemt i en database.</p>]]></content><author><name>David</name></author><summary type="html"><![CDATA[Mht. machine learning, har vi talt med nolek omkring at det kunne bruges til at forudse/gætte hvor sandsynligheden er højest for at lækket sker på et bestemt punkt, ud fra det data virksomheden har. Det kan også være at det bliver et input af lækage data fra deres hardware, som så giver det punkt der har højest risiko for læk (istedet for et enkelt punkt). Det kunne gøres med fx multiple liniar regression, logistisk regression, eller neuralt netværk, regner med at det bliver supervised learning, dvs. labeled data. Det er svært at sige hvordan det præcis bliver inden, men forventer at nolek giver nogle store dataset at arbejde med.]]></summary></entry><entry><title type="html">Delmål Uge 33-34</title><link href="http://localhost:4000/2023/08/15/partgoals.html" rel="alternate" type="text/html" title="Delmål Uge 33-34" /><published>2023-08-15T16:45:13+02:00</published><updated>2023-08-15T16:45:13+02:00</updated><id>http://localhost:4000/2023/08/15/partgoals</id><content type="html" xml:base="http://localhost:4000/2023/08/15/partgoals.html"><![CDATA[<p>Delmål 1: Kunne forstå grundlæggende elementer ved lineær regression, logistisk regression, og neurale netværk → Hvordan vil jeg gøre det? Følge tutorials, blandt andet færdiggøre Codecademy's Introduction to Machine Learning og læse. → Hvornår er det gjort? Når jeg er færdig med Codecademy's tutorial, og jeg har fået en basal viden om emnerne. → Evaluering: Prøve at se, om jeg kan huske teorien, jeg har lært, og hvis ikke, gå tilbage til det jeg ikke kan huske, for at opfriske hukommelsen. Vurder, om jeg har lært nok fra det materiale, jeg har været igennem.</p>

<p>Delmål 2: Lave et simplet ML projekt, måske med et datasæt, der ligner det, som jeg forestiller mig, at Nolek(product owner) har, og tænke over, hvordan et projekt skulle udføres med det datasæt i tankerne. Jeg bruger viden fra foregående læring fra delmål 1 → Hvordan vil jeg gøre det? Bruge viden fra tidligere tutorials → Hvornår er det gjort? Når jeg har prøvet mig frem og har fået trænet en model. → Evaluering: Jeg vil vurdere, om jeg har lært noget, eller bare efterlignet en tutorial, og om jeg har fået et bedre overblik over teorien. Tænker over, hvad der gik godt, og hvad der kan forbedres.</p>

<p>Delmål 3: Kravene til produktet skal være opstillet mht. det produkt jeg skal lave til ”product owner” Nolek → Hvordan? Kravene skal indskrives i et KanBan board. → Hvornår er det gjort? når Kanban boardet er oprettet og overordnet krav er indskrevet</p>
<p>Delmål 4: Skrive omkring hvad jeg lærer på blog-posten → Rediger blog/portefølje </p>
<p>Jeg har overvurderet en smule hvor meget jeg kunne nå. Men jeg fik gjort del 1, 3 og 4:</p>

<img src="/img/posts/partgoals1.png" style="max-width: 100%"> 
<img src="/img/posts/partgoals1part2.png" style="max-width: 100%">]]></content><author><name>David</name></author><summary type="html"><![CDATA[Delmål 1: Kunne forstå grundlæggende elementer ved lineær regression, logistisk regression, og neurale netværk → Hvordan vil jeg gøre det? Følge tutorials, blandt andet færdiggøre Codecademy's Introduction to Machine Learning og læse. → Hvornår er det gjort? Når jeg er færdig med Codecademy's tutorial, og jeg har fået en basal viden om emnerne. → Evaluering: Prøve at se, om jeg kan huske teorien, jeg har lært, og hvis ikke, gå tilbage til det jeg ikke kan huske, for at opfriske hukommelsen. Vurder, om jeg har lært nok fra det materiale, jeg har været igennem.]]></summary></entry></feed>